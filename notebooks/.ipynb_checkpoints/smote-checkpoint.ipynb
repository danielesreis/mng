{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilização da técnica SMOTE para oversampling das imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = os.getcwd()+'//..//features//'\n",
    "path2 = os.getcwd()+'//..//features2//'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(path1+'all_features.csv', sep=',', index_col=0)\n",
    "data2 = pd.read_csv(path2+'all_features.csv', sep=',', index_col=0)\n",
    "\n",
    "sst1 = pd.read_csv(path1+'/../reference_values/primeiros_dados_palmer_sst.csv', sep=',', index_col=0)\n",
    "firmeza1 = pd.read_csv(path1+'/../reference_values/primeiros_dados_palmer_firmeza.csv', sep=',', index_col=0)\n",
    "time1 = pd.read_csv(path1+'/../reference_values/primeiros_dados_palmer_time.csv', sep=',', index_col=0)\n",
    "sst2 = pd.read_csv(path2+'/../reference_values/ultimos_dados_palmer_sst.csv', sep=',', index_col=0)\n",
    "firmeza2 = pd.read_csv(path2+'/../reference_values/ultimos_dados_palmer_firmeza.csv', sep=',', index_col=0)\n",
    "time2 = pd.read_csv(path2+'/../reference_values/ultimos_dados_palmer_time.csv', sep=',', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_append = data1.iloc[600:]\n",
    "sst_to_append = sst1.iloc[600:]\n",
    "firmeza_to_append = firmeza1.iloc[600:]\n",
    "time_to_append = time1.iloc[600:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = set(data1.columns.values)\n",
    "s2 = set(data2.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.difference(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = data2.append(to_append)\n",
    "new_sst = sst2.append(sst_to_append)\n",
    "new_firmeza = firmeza2.append(firmeza_to_append)\n",
    "new_time = time2.append(time_to_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['sst'] = new_sst\n",
    "new_data['firmeza'] = new_firmeza\n",
    "new_data['time'] = new_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "N = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = np.arange(1651,1651+int(new_data.shape[0]*(N/100)))\n",
    "indexes = [str(num)+'_synthetic' for num in nums]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n",
      "[175 167 160 166 162]\n"
     ]
    }
   ],
   "source": [
    "df = smote(new_data, k, N, indexes, 1651, ['time', 'sst', 'firmeza'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote(data, k, N, indexes, i, targets):\n",
    "    N = (int)(N/100)\n",
    "    n_samples = data.shape[0]\n",
    "    features = data.drop(columns=targets)\n",
    "    synthetic = pd.DataFrame(index=indexes,columns=data.columns.values)\n",
    "    \n",
    "    neigh = NearestNeighbors(n_neighbors=k+1)\n",
    "    neigh.fit(features)\n",
    "    \n",
    "#     def treat_targets(neighbors, sample, targets):\n",
    "#         sm = 0\n",
    "#         calc_targ = []\n",
    "        \n",
    "#         for target in targets:\n",
    "#             sm = 0\n",
    "#             for neigh in range(neighbors):\n",
    "#                 sm = sm + (sample[target]-features.iloc[neigh][target])\n",
    "    \n",
    "    def normalize_features():\n",
    "        return features.apply(lambda x: x/np.max(abs(x)))\n",
    "    \n",
    "#     def post_normalize_features():\n",
    "    def get_neighbors(sample):\n",
    "        return neigh.kneighbors([sample], return_distance=False)[0][1:]\n",
    "        \n",
    "    def populate(norm, neighbors, sample, i):\n",
    "        for __ in range(N):\n",
    "            rnd = random.randint(0,k-1)\n",
    "            \n",
    "            diff = features.iloc[neighbors[rnd]] - features.iloc[sample]\n",
    "            gap = random.uniform(0,1)\n",
    "            feature_row = features.iloc[sample] + diff*gap\n",
    "            \n",
    "            synthetic_target = data.iloc[sample][targets]\n",
    "            synthetic_sample = pd.Series(data=feature_row, index=data.columns.values, name=str(i)+'_synthetic')\n",
    "#             print(synthetic_sample)\n",
    "#             print(feature_row)\n",
    "            \n",
    "            for target in targets:\n",
    "                synthetic_sample[target] = data.iloc[sample][target]\n",
    "            \n",
    "            synthetic.loc[str(i)+'_synthetic'] = synthetic_sample\n",
    "            \n",
    "            i=i+1\n",
    "        return i\n",
    "        \n",
    "    norm = normalize_features()\n",
    "    \n",
    "    for sample in range(n_samples):\n",
    "        neighbors = get_neighbors(norm.iloc[sample])\n",
    "        print(neighbors)\n",
    "        i = populate(norm, neighbors, sample, i)\n",
    "    \n",
    "    return synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('synthetic_data.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['sst'] = sst1\n",
    "data1['firmeza'] = firmeza1\n",
    "data1['time'] = time1\n",
    "data2['sst'] = sst2\n",
    "data2['firmeza'] = firmeza2\n",
    "data2['time'] = time2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.getcwd()+'/../resampling/synthetic_data.csv', sep=',', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielesreis/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "all_data = pd.concat([data1, data2, df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv('all_data_synthetic.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = [index.split('_')[0]+'_repeated' for index in indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated = pd.DataFrame(index=indexes, columns=new_data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated.iloc[:240] = new_data.values\n",
    "repeated.iloc[240:] = new_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated['ind'] = indexes\n",
    "repeated.set_index('ind', drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielesreis/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "repeated_data = pd.concat([data1, data2, repeated], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1320, 1935)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeated_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_data.to_csv('all_data_repeated.csv', sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
